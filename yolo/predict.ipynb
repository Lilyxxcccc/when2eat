{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-15T06:52:06.437058Z",
     "start_time": "2025-03-15T06:51:58.254300Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([\"image1.jpg\", \"image2.jpg\"], stream=True)  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m results = model([\u001B[33m\"\u001B[39m\u001B[33mimage1.jpg\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mimage2.jpg\u001B[39m\u001B[33m\"\u001B[39m], stream=\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# return a generator of Results objects\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Process results generator\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresults\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mboxes\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m.\u001B[49m\u001B[43mboxes\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Boxes object for bounding box outputs\u001B[39;49;00m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmasks\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmasks\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Masks object for segmentation masks outputs\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001B[39m, in \u001B[36m_wrap_generator.<locals>.generator_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     34\u001B[39m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[32m     35\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m         response = \u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m     39\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     40\u001B[39m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:295\u001B[39m, in \u001B[36mBasePredictor.stream_inference\u001B[39m\u001B[34m(self, source, model, *args, **kwargs)\u001B[39m\n\u001B[32m    291\u001B[39m     \u001B[38;5;28mself\u001B[39m.setup_model(model)\n\u001B[32m    293\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:  \u001B[38;5;66;03m# for thread-safe inference\u001B[39;00m\n\u001B[32m    294\u001B[39m     \u001B[38;5;66;03m# Setup source every time predict is called\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msetup_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    297\u001B[39m     \u001B[38;5;66;03m# Check if save_dir/ label file exists\u001B[39;00m\n\u001B[32m    298\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save_txt:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:255\u001B[39m, in \u001B[36mBasePredictor.setup_source\u001B[39m\u001B[34m(self, source)\u001B[39m\n\u001B[32m    245\u001B[39m \u001B[38;5;28mself\u001B[39m.imgsz = check_imgsz(\u001B[38;5;28mself\u001B[39m.args.imgsz, stride=\u001B[38;5;28mself\u001B[39m.model.stride, min_dim=\u001B[32m2\u001B[39m)  \u001B[38;5;66;03m# check image size\u001B[39;00m\n\u001B[32m    246\u001B[39m \u001B[38;5;28mself\u001B[39m.transforms = (\n\u001B[32m    247\u001B[39m     \u001B[38;5;28mgetattr\u001B[39m(\n\u001B[32m    248\u001B[39m         \u001B[38;5;28mself\u001B[39m.model.model,\n\u001B[32m   (...)\u001B[39m\u001B[32m    253\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    254\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m255\u001B[39m \u001B[38;5;28mself\u001B[39m.dataset = \u001B[43mload_inference_source\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    256\u001B[39m \u001B[43m    \u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    257\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    258\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvid_stride\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvid_stride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    259\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstream_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    260\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    261\u001B[39m \u001B[38;5;28mself\u001B[39m.source_type = \u001B[38;5;28mself\u001B[39m.dataset.source_type\n\u001B[32m    262\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[32m    263\u001B[39m     \u001B[38;5;28mself\u001B[39m.source_type.stream\n\u001B[32m    264\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.source_type.screenshot\n\u001B[32m    265\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset) > \u001B[32m1000\u001B[39m  \u001B[38;5;66;03m# many images\u001B[39;00m\n\u001B[32m    266\u001B[39m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.dataset, \u001B[33m\"\u001B[39m\u001B[33mvideo_flag\u001B[39m\u001B[33m\"\u001B[39m, [\u001B[38;5;28;01mFalse\u001B[39;00m]))\n\u001B[32m    267\u001B[39m ):  \u001B[38;5;66;03m# videos\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\ultralytics\\data\\build.py:238\u001B[39m, in \u001B[36mload_inference_source\u001B[39m\u001B[34m(source, batch, vid_stride, buffer)\u001B[39m\n\u001B[32m    225\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_inference_source\u001B[39m(source=\u001B[38;5;28;01mNone\u001B[39;00m, batch=\u001B[32m1\u001B[39m, vid_stride=\u001B[32m1\u001B[39m, buffer=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    226\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    227\u001B[39m \u001B[33;03m    Load an inference source for object detection and apply necessary transformations.\u001B[39;00m\n\u001B[32m    228\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    236\u001B[39m \u001B[33;03m        (Dataset): A dataset object for the specified input source with attached source_type attribute.\u001B[39;00m\n\u001B[32m    237\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m238\u001B[39m     source, stream, screenshot, from_img, in_memory, tensor = \u001B[43mcheck_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    239\u001B[39m     source_type = source.source_type \u001B[38;5;28;01mif\u001B[39;00m in_memory \u001B[38;5;28;01melse\u001B[39;00m SourceTypes(stream, screenshot, from_img, tensor)\n\u001B[32m    241\u001B[39m     \u001B[38;5;66;03m# Dataloader\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\ultralytics\\data\\build.py:213\u001B[39m, in \u001B[36mcheck_source\u001B[39m\u001B[34m(source)\u001B[39m\n\u001B[32m    211\u001B[39m     in_memory = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(source, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m     source = \u001B[43mautocast_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# convert all list elements to PIL or np arrays\u001B[39;00m\n\u001B[32m    214\u001B[39m     from_img = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(source, (Image.Image, np.ndarray)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\ultralytics\\data\\loaders.py:593\u001B[39m, in \u001B[36mautocast_list\u001B[39m\u001B[34m(source)\u001B[39m\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m im \u001B[38;5;129;01min\u001B[39;00m source:\n\u001B[32m    592\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(im, (\u001B[38;5;28mstr\u001B[39m, Path)):  \u001B[38;5;66;03m# filename or uri\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m593\u001B[39m         files.append(\u001B[43mImage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequests\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraw\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstartswith\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhttp\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mim\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    594\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(im, (Image.Image, np.ndarray)):  \u001B[38;5;66;03m# PIL or np Image\u001B[39;00m\n\u001B[32m    595\u001B[39m         files.append(im)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Yolo\\whentoeat\\.venv\\Lib\\site-packages\\PIL\\Image.py:3465\u001B[39m, in \u001B[36mopen\u001B[39m\u001B[34m(fp, mode, formats)\u001B[39m\n\u001B[32m   3462\u001B[39m     filename = os.fspath(fp)\n\u001B[32m   3464\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[32m-> \u001B[39m\u001B[32m3465\u001B[39m     fp = \u001B[43mbuiltins\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   3466\u001B[39m     exclusive_fp = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   3467\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'image1.jpg'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
